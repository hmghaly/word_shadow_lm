{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "673c31df-ebf6-4b5f-8d60-91df5dcb7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 0\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0516), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.00046958 0.00052796 0.00017693 0.00024027 0.0001534  0.0005668\n",
      " 0.00040537 0.00034057 0.00012464 0.0002667  0.00027103 0.00050601\n",
      " 0.00038951 0.00056165 0.00294987]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06627407070527176\n",
      "epoch0 1\n",
      "('<s>', 'the')\n",
      "[('noun', 0.1016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.00083409 0.00091359 0.00021396 0.0004195  0.00021133 0.00099836\n",
      " 0.00071702 0.00050602 0.00015642 0.00042219 0.00043363 0.00087081\n",
      " 0.00070829 0.00100526 0.01076397]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06523960938231262\n",
      "epoch0 2\n",
      "('<s>', 'the')\n",
      "[('noun', 0.1516), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.00119859 0.00129923 0.00025098 0.00059873 0.00026927 0.00142991\n",
      " 0.00102867 0.00067147 0.0001882  0.00057769 0.00059622 0.00123561\n",
      " 0.00102707 0.00144886 0.02357808]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06356082311268967\n",
      "epoch0 3\n",
      "('<s>', 'the')\n",
      "[('noun', 0.2016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.0015631  0.00168486 0.000288   0.00077796 0.0003272  0.00186146\n",
      " 0.00134032 0.00083692 0.00021998 0.00073318 0.00075881 0.00160042\n",
      " 0.00134585 0.00189247 0.04139218]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06126334010584844\n",
      "epoch0 4\n",
      "('<s>', 'the')\n",
      "[('noun', 0.2516), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.0019276  0.0020705  0.00032502 0.0009572  0.00038514 0.00229301\n",
      " 0.00165197 0.00100237 0.00025175 0.00088867 0.0009214  0.00196522\n",
      " 0.00166462 0.00233608 0.06420629]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.05838278857123442\n",
      "epoch0 5\n",
      "('<s>', 'the')\n",
      "[('noun', 0.3016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.0022921  0.00245613 0.00036205 0.00113643 0.00044307 0.00272456\n",
      " 0.00196362 0.00116782 0.00028353 0.00104416 0.00108399 0.00233002\n",
      " 0.0019834  0.00277968 0.09202039]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.05496479671829311\n",
      "epoch0 6\n",
      "('<s>', 'the')\n",
      "[('noun', 0.3516), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.00265661 0.00284177 0.00039907 0.00131566 0.00050101 0.00315611\n",
      " 0.00227527 0.00133327 0.00031531 0.00119965 0.00124658 0.00269482\n",
      " 0.00230218 0.00322329 0.1248345 ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.05106499275647\n",
      "epoch0 7\n",
      "('<s>', 'the')\n",
      "[('noun', 0.4016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.00302111 0.0032274  0.00043609 0.0014949  0.00055894 0.00358767\n",
      " 0.00258692 0.00149871 0.00034709 0.00135514 0.00140918 0.00305963\n",
      " 0.00262096 0.0036669  0.1626486 ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.0467490048952106\n",
      "epoch0 8\n",
      "('<s>', 'the')\n",
      "[('noun', 0.4516), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.00338561 0.00361304 0.00047311 0.00167413 0.00061687 0.00401922\n",
      " 0.00289857 0.00166416 0.00037887 0.00151063 0.00157177 0.00342443\n",
      " 0.00293974 0.0041105  0.20546271]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.04209246134396039\n",
      "epoch0 9\n",
      "('<s>', 'the')\n",
      "[('noun', 0.5016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0071)]\n",
      "[0.00375012 0.00399867 0.00051014 0.00185336 0.00067481 0.00445077\n",
      " 0.00321021 0.00182961 0.00041065 0.00166612 0.00173436 0.00378923\n",
      " 0.00325852 0.00455411 0.25327681]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.0371809903121649\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def one_hot(index0,size0):\n",
    "    out0=np.zeros(size0,dtype=np.float32())\n",
    "    out0[index0]=1.\n",
    "    return out0\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "# 1. Input sentences\n",
    "sentences = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"a small dog ran quickly\",\n",
    "    \"the big cat jumped over the dog\"\n",
    "]\n",
    "\n",
    "vocab_count_dict={}\n",
    "bigram_list=[]\n",
    "for sent0 in sentences:\n",
    "    sent_tokens0=re.findall(\"\\w+\",sent0.lower())\n",
    "    padded_tokens0=[\"<s>\"]+sent_tokens0+[\"</s>\"]\n",
    "    for tk0 in padded_tokens0:\n",
    "        vocab_count_dict[tk0]=vocab_count_dict.get(tk0,0)+1\n",
    "    cur_bigrams0=[(padded_tokens0[i],padded_tokens0[i+1]) for i in range(len(padded_tokens0)-1)]\n",
    "    bigram_list.extend(cur_bigrams0)\n",
    "    # print(padded_tokens0)\n",
    "    # print(cur_bigrams0)\n",
    "# for a,b in vocab_count_dict.items():\n",
    "#     print(a,b)\n",
    "\n",
    "# 2. Preprocess\n",
    "# corpus = \" \".join(sentences).lower().split()\n",
    "vocab = sorted(list(set(vocab_count_dict.keys() )))\n",
    "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "V = len(vocab)\n",
    "\n",
    "#print(vocab)\n",
    "\n",
    "# # 3. Predefined features\n",
    "#features = [\"content_word\", \"function_word\"]\n",
    "features = [\"noun\", \"verb\",\"det\",\"prep\",\"other\"]\n",
    "K = len(features)\n",
    "\n",
    "# 4. Initialize parameters\n",
    "np.random.seed(42)\n",
    "F_raw = np.random.rand(V, K) * 0.01  # raw feature weights before sigmoid - try np.random.randn at some point\n",
    "T = np.random.rand(K, V) * 0.01      # transition matrix\n",
    "\n",
    "# print(T.shape)\n",
    "# print(F_raw)\n",
    "lr = 0.05  # learning rate\n",
    "\n",
    "cur_word0=\"<s>\"\n",
    "target_word0=\"the\"\n",
    "#cur_tag0=\"other\"\n",
    "cur_tag0=\"noun\"\n",
    "\n",
    "tag_i=features.index(cur_tag0)\n",
    "cur_i=word_to_idx[cur_word0]\n",
    "target_i=word_to_idx[target_word0]\n",
    "\n",
    "F_raw[cur_i][tag_i]+=lr\n",
    "T[tag_i][target_i]+=lr\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "for epoch0 in range(n_epochs):\n",
    "    print(\"epoch0\",epoch0)\n",
    "    for big0 in bigram_list[:1]:\n",
    "        print(big0)\n",
    "        first0,second0=big0\n",
    "        first_i0,second_i0=word_to_idx[first0],word_to_idx[second0]\n",
    "        #print(first_i0,second_i0)\n",
    "        row0=first_wts=F_raw[first_i0]\n",
    "        \n",
    "        ft_wts=[(ft0,round(float(ft_wt0) ,4)) for ft0,ft_wt0 in zip(features,row0)]\n",
    "        print(ft_wts)\n",
    "        \n",
    "        #print(first_wts.shape)\n",
    "        actual0=one_hot(second_i0,V)\n",
    "        pred0=first_wts @ T\n",
    "        loss0=mean_squared_error(pred0,actual0)\n",
    "        print(pred0)\n",
    "        print(actual0)\n",
    "        print(loss0)\n",
    "    F_raw[cur_i][tag_i]+=lr\n",
    "    T[tag_i][target_i]+=lr\n",
    "\n",
    "\n",
    "\n",
    "#final checking\n",
    "for i0,row0 in enumerate(F_raw):\n",
    "    word0=idx_to_word[i0]\n",
    "    ft_wts=[(ft0,round(float(ft_wt0) ,4)) for ft0,ft_wt0 in zip(features,row0)]\n",
    "    #print(i0,word0,ft_wts)\n",
    "\n",
    "# # 5. Activation functions\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def sigmoid_deriv(sig):\n",
    "#     return sig * (1 - sig)\n",
    "\n",
    "# def softmax(x):\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "#     return e_x / np.sum(e_x)\n",
    "\n",
    "# # 6. Training loop\n",
    "# epochs = 50\n",
    "# for epoch in range(epochs):\n",
    "#     total_loss = 0\n",
    "#     for i in range(len(corpus) - 1):\n",
    "#         w_curr = word_to_idx[corpus[i]]\n",
    "#         w_next = word_to_idx[corpus[i + 1]]\n",
    "\n",
    "#         # Forward pass\n",
    "#         F_sigmoid = sigmoid(F_raw[w_curr])       # apply sigmoid: shape (K,)\n",
    "#         logits = F_sigmoid @ T                   # shape (V,)\n",
    "#         probs = softmax(logits)                  # shape (V,)\n",
    "\n",
    "#         # Loss (cross-entropy)\n",
    "#         loss = -np.log(probs[w_next] + 1e-9)\n",
    "#         total_loss += loss\n",
    "\n",
    "#         # Backward pass\n",
    "#         dlogits = probs.copy()\n",
    "#         dlogits[w_next] -= 1  # dL/dlogits\n",
    "\n",
    "#         dT = np.outer(F_sigmoid, dlogits)                # dL/dT: (K, V)\n",
    "#         dF_sigmoid = T @ dlogits                         # dL/d(sigmoid(F_raw)): shape (K,)\n",
    "#         dF_raw = dF_sigmoid * sigmoid_deriv(F_sigmoid)   # dL/dF_raw using sigmoid chain rule\n",
    "\n",
    "#         # Parameter updates\n",
    "#         T -= lr * dT\n",
    "#         F_raw[w_curr] -= lr * dF_raw\n",
    "\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d1c990e-ab17-4735-b4d9-df55384b3174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.06664857887212164\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50bf05-feed-4404-90fe-56e88e5ee505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
