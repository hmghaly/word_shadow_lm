{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "673c31df-ebf6-4b5f-8d60-91df5dcb7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 0\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.0571)]\n",
      "[0.00026668 0.00040172 0.00049142 0.00024285 0.00058136 0.00061648\n",
      " 0.00021962 0.00042375 0.0002433  0.00025363 0.00012689 0.00044599\n",
      " 0.00032207 0.00014378 0.00312912]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06625023237621361\n",
      "epoch0 1\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.1071)]\n",
      "[0.00042828 0.00066111 0.00084293 0.00042466 0.00106725 0.0010977\n",
      " 0.00034551 0.00067237 0.00039374 0.00039605 0.00014533 0.00075077\n",
      " 0.00057341 0.00016952 0.01112248]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06519229493960911\n",
      "epoch0 2\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.1571)]\n",
      "[0.00058989 0.00092051 0.00119444 0.00060648 0.00155314 0.00157892\n",
      " 0.0004714  0.00092099 0.00054418 0.00053847 0.00016377 0.00105555\n",
      " 0.00082475 0.00019526 0.02411584]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06349075328135016\n",
      "epoch0 3\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.2071)]\n",
      "[0.00075149 0.0011799  0.00154595 0.00078829 0.00203903 0.00206015\n",
      " 0.00059729 0.00116962 0.00069462 0.00068089 0.00018222 0.00136033\n",
      " 0.00107609 0.000221   0.0421092 ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.06117159412047883\n",
      "epoch0 4\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.2571)]\n",
      "[0.00091309 0.0014393  0.00189746 0.00097011 0.00252492 0.00254137\n",
      " 0.00072318 0.00141824 0.00084505 0.00082331 0.00020066 0.00166511\n",
      " 0.00132743 0.00024674 0.06510256]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.05827080417603711\n",
      "epoch0 5\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.3071)]\n",
      "[0.00107469 0.00169869 0.00224897 0.00115192 0.00301081 0.00302259\n",
      " 0.00084907 0.00166687 0.00099549 0.00096573 0.0002191  0.0019699\n",
      " 0.00157877 0.00027248 0.09309592]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.05483437016706705\n",
      "epoch0 6\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.3571)]\n",
      "[0.00123629 0.00195809 0.00260048 0.00133374 0.0034967  0.00350382\n",
      " 0.00097496 0.00191549 0.00114593 0.00110815 0.00023755 0.00227468\n",
      " 0.00183011 0.00029822 0.12608928]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.05091827881261068\n",
      "epoch0 7\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.4071)]\n",
      "[0.00139789 0.00221748 0.00295199 0.00151555 0.00398259 0.00398504\n",
      " 0.00110085 0.00216412 0.00129637 0.00125057 0.00025599 0.00257946\n",
      " 0.00208145 0.00032396 0.16408264]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.04658851683171004\n",
      "epoch0 8\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.4571)]\n",
      "[0.00155949 0.00247688 0.0033035  0.00169737 0.00446848 0.00446626\n",
      " 0.00122674 0.00241274 0.00144681 0.00139299 0.00027443 0.00288424\n",
      " 0.00233279 0.0003497  0.207076  ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.041921070943407135\n",
      "epoch0 9\n",
      "('<s>', 'the')\n",
      "[('noun', 0.0016), ('verb', 0.0006), ('det', 0.0087), ('prep', 0.006), ('other', 0.5071)]\n",
      "[0.0017211  0.00273627 0.00365501 0.00187918 0.00495437 0.00494749\n",
      " 0.00135264 0.00266136 0.00159725 0.00153541 0.00029288 0.00318902\n",
      " 0.00258413 0.00037544 0.25506936]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.03700192786674404\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def one_hot(index0,size0):\n",
    "    out0=np.zeros(size0,dtype=np.float32())\n",
    "    out0[index0]=1.\n",
    "    return out0\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "# 1. Input sentences\n",
    "sentences = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"a small dog ran quickly\",\n",
    "    \"the big cat jumped over the dog\"\n",
    "]\n",
    "\n",
    "vocab_count_dict={}\n",
    "bigram_list=[]\n",
    "for sent0 in sentences:\n",
    "    sent_tokens0=re.findall(\"\\w+\",sent0.lower())\n",
    "    padded_tokens0=[\"<s>\"]+sent_tokens0+[\"</s>\"]\n",
    "    for tk0 in padded_tokens0:\n",
    "        vocab_count_dict[tk0]=vocab_count_dict.get(tk0,0)+1\n",
    "    cur_bigrams0=[(padded_tokens0[i],padded_tokens0[i+1]) for i in range(len(padded_tokens0)-1)]\n",
    "    bigram_list.extend(cur_bigrams0)\n",
    "    # print(padded_tokens0)\n",
    "    # print(cur_bigrams0)\n",
    "# for a,b in vocab_count_dict.items():\n",
    "#     print(a,b)\n",
    "\n",
    "# 2. Preprocess\n",
    "# corpus = \" \".join(sentences).lower().split()\n",
    "vocab = sorted(list(set(vocab_count_dict.keys() )))\n",
    "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "V = len(vocab)\n",
    "\n",
    "#print(vocab)\n",
    "\n",
    "# # 3. Predefined features\n",
    "#features = [\"content_word\", \"function_word\"]\n",
    "features = [\"noun\", \"verb\",\"det\",\"prep\",\"other\"]\n",
    "K = len(features)\n",
    "\n",
    "# 4. Initialize parameters\n",
    "np.random.seed(42)\n",
    "F_raw = np.random.rand(V, K) * 0.01  # raw feature weights before sigmoid - try np.random.randn at some point\n",
    "T = np.random.rand(K, V) * 0.01      # transition matrix\n",
    "\n",
    "# print(T.shape)\n",
    "# print(F_raw)\n",
    "lr = 0.05  # learning rate\n",
    "\n",
    "cur_word0=\"<s>\"\n",
    "target_word0=\"the\"\n",
    "cur_tag0=\"other\"\n",
    "\n",
    "tag_i=features.index(cur_tag0)\n",
    "cur_i=word_to_idx[cur_word0]\n",
    "target_i=word_to_idx[target_word0]\n",
    "\n",
    "F_raw[cur_i][tag_i]+=lr\n",
    "T[tag_i][target_i]+=lr\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "for epoch0 in range(n_epochs):\n",
    "    print(\"epoch0\",epoch0)\n",
    "    for big0 in bigram_list[:1]:\n",
    "        print(big0)\n",
    "        first0,second0=big0\n",
    "        first_i0,second_i0=word_to_idx[first0],word_to_idx[second0]\n",
    "        #print(first_i0,second_i0)\n",
    "        row0=first_wts=F_raw[first_i0]\n",
    "        \n",
    "        ft_wts=[(ft0,round(float(ft_wt0) ,4)) for ft0,ft_wt0 in zip(features,row0)]\n",
    "        print(ft_wts)\n",
    "        \n",
    "        #print(first_wts.shape)\n",
    "        actual0=one_hot(second_i0,V)\n",
    "        pred0=first_wts @ T\n",
    "        loss0=mean_squared_error(pred0,actual0)\n",
    "        print(pred0)\n",
    "        print(actual0)\n",
    "        print(loss0)\n",
    "    F_raw[cur_i][tag_i]+=lr\n",
    "    T[tag_i][target_i]+=lr\n",
    "\n",
    "\n",
    "\n",
    "#final checking\n",
    "for i0,row0 in enumerate(F_raw):\n",
    "    word0=idx_to_word[i0]\n",
    "    ft_wts=[(ft0,round(float(ft_wt0) ,4)) for ft0,ft_wt0 in zip(features,row0)]\n",
    "    #print(i0,word0,ft_wts)\n",
    "\n",
    "# # 5. Activation functions\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def sigmoid_deriv(sig):\n",
    "#     return sig * (1 - sig)\n",
    "\n",
    "# def softmax(x):\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "#     return e_x / np.sum(e_x)\n",
    "\n",
    "# # 6. Training loop\n",
    "# epochs = 50\n",
    "# for epoch in range(epochs):\n",
    "#     total_loss = 0\n",
    "#     for i in range(len(corpus) - 1):\n",
    "#         w_curr = word_to_idx[corpus[i]]\n",
    "#         w_next = word_to_idx[corpus[i + 1]]\n",
    "\n",
    "#         # Forward pass\n",
    "#         F_sigmoid = sigmoid(F_raw[w_curr])       # apply sigmoid: shape (K,)\n",
    "#         logits = F_sigmoid @ T                   # shape (V,)\n",
    "#         probs = softmax(logits)                  # shape (V,)\n",
    "\n",
    "#         # Loss (cross-entropy)\n",
    "#         loss = -np.log(probs[w_next] + 1e-9)\n",
    "#         total_loss += loss\n",
    "\n",
    "#         # Backward pass\n",
    "#         dlogits = probs.copy()\n",
    "#         dlogits[w_next] -= 1  # dL/dlogits\n",
    "\n",
    "#         dT = np.outer(F_sigmoid, dlogits)                # dL/dT: (K, V)\n",
    "#         dF_sigmoid = T @ dlogits                         # dL/d(sigmoid(F_raw)): shape (K,)\n",
    "#         dF_raw = dF_sigmoid * sigmoid_deriv(F_sigmoid)   # dL/dF_raw using sigmoid chain rule\n",
    "\n",
    "#         # Parameter updates\n",
    "#         T -= lr * dT\n",
    "#         F_raw[w_curr] -= lr * dF_raw\n",
    "\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d1c990e-ab17-4735-b4d9-df55384b3174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.06664857887212164\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50bf05-feed-4404-90fe-56e88e5ee505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
